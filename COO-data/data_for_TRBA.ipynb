{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0203e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import manga109api\n",
    "from natsort import natsorted\n",
    "\n",
    "def crop_word_boxes(root_path, data_split, hardROI=False):\n",
    "\n",
    "    manga109_root_path = root_path\n",
    "    manga109_parser = manga109api.Parser(root_dir=manga109_root_path)\n",
    "    annotation_type = \"annotations\"\n",
    "\n",
    "    with open(f'./books_{data_split}.txt', 'r', encoding='utf-8-sig') as manga_onomatopoeia_split:\n",
    "        manga_onomatopoeia_split_books = manga_onomatopoeia_split.readlines()\n",
    "\n",
    "    print(\"The number of mangas:\", len(manga_onomatopoeia_split_books))\n",
    "    # Precomputing total image count\n",
    "    total_image_count = 0\n",
    "    for manga_name in manga_onomatopoeia_split_books:\n",
    "        manga_name = manga_name.strip()\n",
    "        annotation = manga109_parser.get_annotation(book=manga_name, annotation_type=annotation_type)\n",
    "        total_image_count += len(annotation[\"page\"])\n",
    "    print(\"The number of scene images:\", total_image_count)\n",
    "\n",
    "    image_count = 0\n",
    "    word_count = 0\n",
    "    if hardROI:\n",
    "        word_gt_path = os.path.join(root_path, f\"TRBA_data/gt_{data_split}_hardROI.txt\")\n",
    "    else:\n",
    "        word_gt_path = os.path.join(root_path, f\"TRBA_data/gt_{data_split}.txt\")\n",
    "    os.makedirs(os.path.join(root_path, \"TRBA_data\"), exist_ok=True)\n",
    "        \n",
    "    with open(word_gt_path, 'w', encoding='utf-8') as word_gt:\n",
    "        for manga_name in natsorted(manga_onomatopoeia_split_books):\n",
    "            manga_name = manga_name.strip()\n",
    "            if hardROI:\n",
    "                image_output_path = os.path.join(root_path, f\"TRBA_data/{data_split}_hardROI/{manga_name}/\")\n",
    "            else:\n",
    "                image_output_path = os.path.join(root_path, f\"TRBA_data/{data_split}/{manga_name}/\")\n",
    "            os.makedirs(image_output_path, exist_ok=True)\n",
    "\n",
    "            annotation = manga109_parser.get_annotation(book=manga_name, annotation_type=annotation_type)\n",
    "\n",
    "            for page_index in range(len(annotation[\"page\"])):\n",
    "\n",
    "                image_count += 1\n",
    "                if image_count % 200 == 0:\n",
    "                    print(f'{image_count} images are cropped')\n",
    "\n",
    "                image_path = manga109_parser.img_path(book=manga_name, index=page_index)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                try:\n",
    "                    rois = annotation['page'][page_index][\"onomatopoeia\"]\n",
    "                    if isinstance(rois, dict):\n",
    "                        rois = [rois]  # for one instance case.\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                cnt = 0\n",
    "                for roi in rois:\n",
    "                    x_list = [int(roi[attr]) for attr in roi if '@x' in attr]\n",
    "                    y_list = [int(roi[attr]) for attr in roi if '@y' in attr]\n",
    "\n",
    "                    # when the label only have top-left and bottom-right points of rectangle.\n",
    "                    if len(x_list) == 2:\n",
    "                        x_list = [x_list[0], x_list[1], x_list[1], x_list[0]]\n",
    "                        y_list = [y_list[0], y_list[0], y_list[1], y_list[1]]\n",
    "\n",
    "                    # polygon = [(x, y) for x, y in zip(x_list, y_list)]\n",
    "                    polygon = []\n",
    "                    for x, y in zip(x_list, y_list):\n",
    "                        polygon.append(x)\n",
    "                        polygon.append(y)\n",
    "                  \n",
    "                    label = roi['#text']\n",
    "\n",
    "                    try:\n",
    "                        xmin = min(x_list)\n",
    "                        ymin = min(y_list)\n",
    "                        xmax = max(x_list)\n",
    "                        ymax = max(y_list)\n",
    "                        word_box = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                        if hardROI:\n",
    "                            #print(word_box.shape, xmin, ymin)\n",
    "                            w = xmax - xmin\n",
    "                            h = ymax - ymin\n",
    "                            polygon = np.array(polygon, np.int32)\n",
    "                            polygon[0::2] -= xmin\n",
    "                            polygon[1::2] -= ymin\n",
    "                            polygon = polygon.reshape((-1, 1, 2))\n",
    "                            M = np.zeros([h, w])\n",
    "                            cv2.fillPoly(M, [polygon], 1)\n",
    "                            M = np.stack([M, M, M], axis=2)\n",
    "                            word_box = word_box * M\n",
    "\n",
    "                    except:\n",
    "                        word_box = None\n",
    "                        print('corrupt image?', image_path)\n",
    "                        continue\n",
    "\n",
    "                    word_box_name = str(page_index) + \"-\" + str(cnt)\n",
    "                    word_box_path = os.path.join(image_output_path, word_box_name + \".jpg\")\n",
    "                    cv2.imwrite(word_box_path, word_box)\n",
    "                    \n",
    "                    if hardROI:\n",
    "                        word_gt.write(f'TRBA_data/{data_split}_hardROI/{manga_name}/{word_box_name}.jpg\\t{label}\\n')\n",
    "                    else:\n",
    "                        word_gt.write(f'TRBA_data/{data_split}/{manga_name}/{word_box_name}.jpg\\t{label}\\n')\n",
    "\n",
    "                    cnt += 1\n",
    "                    word_count += 1\n",
    "                    if word_count % 50000 == 0:\n",
    "                        print(f'{word_count} words are cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af55ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for create lmdb\n",
    "import os\n",
    "import random\n",
    "\n",
    "import lmdb\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def checkImageIsValid(imageBin):\n",
    "    if imageBin is None:\n",
    "        return False\n",
    "    imageBuf = np.frombuffer(imageBin, dtype=np.uint8)\n",
    "    img = cv2.imdecode(imageBuf, cv2.IMREAD_GRAYSCALE)\n",
    "    imgH, imgW = img.shape[0], img.shape[1]\n",
    "    if imgH * imgW == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def writeCache(env, cache):\n",
    "    with env.begin(write=True) as txn:\n",
    "        for k, v in cache.items():\n",
    "            txn.put(k, v)\n",
    "\n",
    "\n",
    "def createDataset(inputPath, gtFile, outputPath, checkValid=True):\n",
    "    \"\"\"a modified version of CRNN torch repository https://github.com/bgshih/crnn/blob/master/tool/create_dataset.py\n",
    "    Create LMDB dataset for training and evaluation.\n",
    "    ARGS:\n",
    "        inputPath  : input folder path where starts imagePath\n",
    "        outputPath : LMDB output path\n",
    "        gtFile     : list of image path and label\n",
    "        checkValid : if true, check the validity of every image\n",
    "    \"\"\"\n",
    "    # CAUTION: if outputPath (lmdb) already exists, this function add dataset\n",
    "    # into it. so remove former one and re-create lmdb.\n",
    "    if os.path.exists(outputPath):\n",
    "        os.system(f\"rm -r {outputPath}\")\n",
    "\n",
    "    os.makedirs(outputPath, exist_ok=True)\n",
    "    env = lmdb.open(outputPath, map_size=30 * 2 ** 30)\n",
    "    cache = {}\n",
    "    cnt = 1\n",
    "\n",
    "    with open(gtFile, \"r\", encoding=\"utf-8-sig\") as data:\n",
    "        datalist = data.readlines()\n",
    "\n",
    "    nSamples = len(datalist)\n",
    "    for i in tqdm(range(nSamples), total=nSamples, position=0, leave=True):\n",
    "        imagePath, label = datalist[i].strip(\"\\n\").split(\"\\t\")\n",
    "        imagePath = os.path.join(inputPath, imagePath)\n",
    "\n",
    "        if not os.path.exists(imagePath):\n",
    "            print(\"%s does not exist\" % imagePath)\n",
    "            continue\n",
    "        with open(imagePath, \"rb\") as f:\n",
    "            imageBin = f.read()\n",
    "        if checkValid:\n",
    "            try:\n",
    "                if not checkImageIsValid(imageBin):\n",
    "                    print(\"%s is not a valid image\" % imagePath)\n",
    "                    continue\n",
    "            except:\n",
    "                print(\"error occured\", i)\n",
    "                with open(outputPath + \"/error_image_log.txt\", \"a\") as log:\n",
    "                    log.write(\"%s-th image data occured error\\n\" % str(i))\n",
    "                continue\n",
    "\n",
    "        imageKey = \"image-%09d\".encode() % cnt\n",
    "        imagepathKey = \"imagepath-%09d\".encode() % cnt\n",
    "        labelKey = \"label-%09d\".encode() % cnt\n",
    "        cache[imageKey] = imageBin\n",
    "        cache[labelKey] = label.encode()\n",
    "        cache[imagepathKey] = imagePath.encode()\n",
    "\n",
    "        if cnt % 1000 == 0:\n",
    "            writeCache(env, cache)\n",
    "            cache = {}\n",
    "            # print('Written %d / %d' % (cnt, nSamples))\n",
    "        cnt += 1\n",
    "    nSamples = cnt - 1\n",
    "    cache[\"num-samples\".encode()] = str(nSamples).encode()\n",
    "    writeCache(env, cache)\n",
    "    print(\"Created dataset with %d samples\" % nSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f7823b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mangas: 89\n",
      "The number of scene images: 8763\n",
      "200 images are cropped\n",
      "400 images are cropped\n",
      "600 images are cropped\n",
      "800 images are cropped\n",
      "1000 images are cropped\n",
      "1200 images are cropped\n",
      "1400 images are cropped\n",
      "1600 images are cropped\n",
      "1800 images are cropped\n",
      "2000 images are cropped\n",
      "2200 images are cropped\n",
      "2400 images are cropped\n",
      "2600 images are cropped\n",
      "2800 images are cropped\n",
      "3000 images are cropped\n",
      "3200 images are cropped\n",
      "3400 images are cropped\n",
      "3600 images are cropped\n",
      "3800 images are cropped\n",
      "4000 images are cropped\n",
      "4200 images are cropped\n",
      "4400 images are cropped\n",
      "4600 images are cropped\n",
      "4800 images are cropped\n",
      "5000 images are cropped\n",
      "5200 images are cropped\n",
      "5400 images are cropped\n",
      "5600 images are cropped\n",
      "5800 images are cropped\n",
      "6000 images are cropped\n",
      "6200 images are cropped\n",
      "6400 images are cropped\n",
      "6600 images are cropped\n",
      "6800 images are cropped\n",
      "7000 images are cropped\n",
      "7200 images are cropped\n",
      "7400 images are cropped\n",
      "7600 images are cropped\n",
      "7800 images are cropped\n",
      "8000 images are cropped\n",
      "8200 images are cropped\n",
      "8400 images are cropped\n",
      "8600 images are cropped\n",
      "50000 words are cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 50064/50064 [01:47<00:00, 465.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 50064 samples\n",
      "The number of mangas: 10\n",
      "The number of scene images: 890\n",
      "200 images are cropped\n",
      "400 images are cropped\n",
      "600 images are cropped\n",
      "800 images are cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4636/4636 [00:10<00:00, 443.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 4636 samples\n",
      "The number of mangas: 10\n",
      "The number of scene images: 949\n",
      "200 images are cropped\n",
      "400 images are cropped\n",
      "600 images are cropped\n",
      "800 images are cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 6765/6765 [00:12<00:00, 525.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 6765 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_split_list = [\"train\", \"val\", \"test\"]\n",
    "hardROI = False\n",
    "\n",
    "for data_split in data_split_list:\n",
    "#     root_path = f'./onomatopoeia_data/'\n",
    "    root_path = f'.'\n",
    "    crop_word_boxes(root_path, data_split, hardROI=hardROI)\n",
    "\n",
    "    inputPath = f'.'\n",
    "    if hardROI:\n",
    "        gtFile = f'{inputPath}/TRBA_data/gt_{data_split}_hardROI.txt'\n",
    "        outputPath = f'./TRBA_data/hardROI/{data_split}'\n",
    "    else:\n",
    "        gtFile = f'{inputPath}/TRBA_data/gt_{data_split}.txt'\n",
    "        outputPath = f'./TRBA_data/lmdb/{data_split}'\n",
    "    createDataset(inputPath, gtFile, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47e5eaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mangas: 89\n",
      "The number of scene images: 8763\n",
      "200 images are cropped\n",
      "400 images are cropped\n",
      "600 images are cropped\n",
      "800 images are cropped\n",
      "1000 images are cropped\n",
      "1200 images are cropped\n",
      "1400 images are cropped\n",
      "1600 images are cropped\n",
      "1800 images are cropped\n",
      "2000 images are cropped\n",
      "2200 images are cropped\n",
      "2400 images are cropped\n",
      "2600 images are cropped\n",
      "2800 images are cropped\n",
      "3000 images are cropped\n",
      "3200 images are cropped\n",
      "3400 images are cropped\n",
      "3600 images are cropped\n",
      "3800 images are cropped\n",
      "4000 images are cropped\n",
      "4200 images are cropped\n",
      "4400 images are cropped\n",
      "4600 images are cropped\n",
      "4800 images are cropped\n",
      "5000 images are cropped\n",
      "5200 images are cropped\n",
      "5400 images are cropped\n",
      "5600 images are cropped\n",
      "5800 images are cropped\n",
      "6000 images are cropped\n",
      "6200 images are cropped\n",
      "6400 images are cropped\n",
      "6600 images are cropped\n",
      "6800 images are cropped\n",
      "7000 images are cropped\n",
      "7200 images are cropped\n",
      "7400 images are cropped\n",
      "7600 images are cropped\n",
      "7800 images are cropped\n",
      "8000 images are cropped\n",
      "8200 images are cropped\n",
      "8400 images are cropped\n",
      "8600 images are cropped\n",
      "50000 words are cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 50064/50064 [01:39<00:00, 503.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 50064 samples\n",
      "The number of mangas: 10\n",
      "The number of scene images: 890\n",
      "200 images are cropped\n",
      "400 images are cropped\n",
      "600 images are cropped\n",
      "800 images are cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4636/4636 [00:12<00:00, 370.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 4636 samples\n",
      "The number of mangas: 10\n",
      "The number of scene images: 949\n",
      "200 images are cropped\n",
      "400 images are cropped\n",
      "600 images are cropped\n",
      "800 images are cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 6765/6765 [00:13<00:00, 509.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 6765 samples\n"
     ]
    }
   ],
   "source": [
    "# for hardROI data\n",
    "data_split_list = [\"train\", \"val\", \"test\"]\n",
    "hardROI = True\n",
    "\n",
    "for data_split in data_split_list:\n",
    "    root_path = f'.'\n",
    "    crop_word_boxes(root_path, data_split, hardROI=hardROI)\n",
    "\n",
    "    inputPath = f'.'\n",
    "    if hardROI:\n",
    "        gtFile = f'{inputPath}/TRBA_data/gt_{data_split}_hardROI.txt'\n",
    "        outputPath = f'./TRBA_data/hardROI/{data_split}'\n",
    "    else:\n",
    "        gtFile = f'{inputPath}/TRBA_data/gt_{data_split}.txt'\n",
    "        outputPath = f'./TRBA_data/lmdb/{data_split}'\n",
    "    createDataset(inputPath, gtFile, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38b6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
